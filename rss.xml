<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Alessandro's View</title><link>https://alexpacio.github.io/</link><description>Engineer sharing insights on cloud-native technologies, Kubernetes, networking, and development practices.</description><atom:link href="https://alexpacio.github.io/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="mailto:alexpacio91 at gmail dot com"&gt;Alessandro Bolletta&lt;/a&gt; </copyright><lastBuildDate>Sun, 24 Aug 2025 19:00:31 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>On the Phenomenology of Coding Agents</title><link>https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;div&gt;&lt;p&gt;Large Language Models have undoubtedly revolutionized how we interact with technology. They are, at their core, supercharged search engines with remarkable encoding and decoding capabilities. You speak to them in natural language, and they respond with perfect written text, flawless speech synthesis, or sophisticated image generation. Their utility is undeniable, yet we must acknowledge a fundamental truth: they cannot think in the human sense of the word.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>ai</category><category>coding</category><category>development</category><category>llm</category><category>programming</category><guid>https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/</guid><pubDate>Sun, 24 Aug 2025 10:00:00 GMT</pubDate></item><item><title>MySQL GTID, Semi-Sync Replication and Partial View Caching: A good compromise to scale easy and cheap</title><link>https://alexpacio.github.io/posts/mysql-gtid-and-semi-sync-replication/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;div&gt;&lt;p&gt;For various reasons, I have often been involved in resolving infrastructural issues and performance gaps in MySQL deployments. I never envisioned my career focusing on database systems, yet it seems there is still a high demand for OLTP technologies in the Italian market, so here I am.&lt;/p&gt;
&lt;p&gt;When you deal with a large dataset (over 500GB) with huge tables (more than 100 million rows), it's not hard to face performance issues. While many solutions exist for running analytical queries (OLAP) on large datasets by leveraging distributed systems, they are not typically "real-time" systems and often operate on stale data. When you have numerous, complex analytical queries — or expensive operations like &lt;em&gt;COUNT(DISTINCT)&lt;/em&gt; — hat must be submitted against a fresh, real-time system, you have no choice: you need to run them on your OLTP engine.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/mysql-gtid-and-semi-sync-replication/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>caching</category><category>database</category><category>gtid</category><category>mysql</category><category>performance</category><category>proxysql</category><category>readyset</category><category>replication</category><guid>https://alexpacio.github.io/posts/mysql-gtid-and-semi-sync-replication/</guid><pubDate>Sun, 03 Aug 2025 16:01:13 GMT</pubDate></item><item><title>Embracing the IPv6 Revolution: A Homelab Story</title><link>https://alexpacio.github.io/posts/embracing-the-ipv6-revolution-a-homelab-story/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;div&gt;&lt;p&gt;The other day, I was contacted by a friend of mine asking for help setting up a home NAS (aka Network Attached Storage) based on OpenMediaVault. While he's an enthusiast, he wasn't able to properly configure all the technical aspects of the setup.&lt;/p&gt;
&lt;p&gt;The NAS world is increasingly resembling a homelab rather than just file storage. Using Docker, you can get enterprise-grade software and setups running with quite simple steps.&lt;/p&gt;
&lt;p&gt;After setting up the Docker containers, we faced the usual issue that most homelabs encounter these days: his internet connection was behind a CGNAT for IPv4 networking. However, I was pleasantly surprised to find an IPv6 public subnet already configured!&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/embracing-the-ipv6-revolution-a-homelab-story/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>cgnat</category><category>Docker</category><category>homelab</category><category>internet</category><category>ipv6</category><category>nas</category><category>networking</category><category>openmediavault</category><guid>https://alexpacio.github.io/posts/embracing-the-ipv6-revolution-a-homelab-story/</guid><pubDate>Fri, 30 May 2025 10:00:00 GMT</pubDate></item><item><title>The Hidden Costs of Static Linking and Containerization: A Critical Analysis</title><link>https://alexpacio.github.io/posts/hidden-costs-static-linking-containerization/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;section id="statically-linked-programs-are-the-evil"&gt;
&lt;h2&gt;Statically-linked Programs are the evil&lt;/h2&gt;
&lt;p&gt;The trend toward static linking represents a fundamental regression in software engineering principles. By bundling every dependency directly into the executable, we're not just bloating our binaries - we're actively dismantling decades of progress in software modularization. Each statically linked program becomes an island, disconnected from the ecosystem of shared improvements and security updates.&lt;/p&gt;
&lt;p&gt;Consider what happens when a critical vulnerability is discovered in a commonly used library. In a properly designed system using shared libraries, a single system update would protect all applications simultaneously. Instead, with static linking, we must embark on a complex and error-prone process of identifying every affected program, rebuilding each one individually, and ensuring they all get redeployed.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/hidden-costs-static-linking-containerization/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/section&gt;</description><category>containers</category><category>development</category><category>infrastructure</category><category>security</category><category>static-linking</category><guid>https://alexpacio.github.io/posts/hidden-costs-static-linking-containerization/</guid><pubDate>Sun, 02 Feb 2025 07:00:00 GMT</pubDate></item><item><title>Exchanging messages between processes (or even threads within the same program) using ZeroMQ</title><link>https://alexpacio.github.io/posts/message-exchanges-using-zeromq/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;section id="inter-process-communication-with-zeromq-and-protocol-buffers"&gt;
&lt;h2&gt;Inter-Process Communication with ZeroMQ (and Protocol Buffers)&lt;/h2&gt;
&lt;section id="introduction"&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Some may certainly say that, when you are writing so called "daemons" under Linux/Unix OSes or "services" under Windows, you might want to use OS primitives/reuse existing libraries to make your programs communicate each other. And I strongly agree with the point: it is always a good idea to use a well-tested and solid library to implement such fundamental features such as message queues.&lt;/p&gt;
&lt;p&gt;For example, under Linux you can use D-Bus, which allows IPC at scale within the OS scope. Or, in the microservices space, you can leverage on message brokers like RabbitMQ or Kafka to stream your messages through sophisticated routing logic. However, at times you are just looking for something trivial and simple to send and queue messages where at the same time you look for brokerless setup but still you are willing to leverage on some of the features that message queuing systems offer for free with ease. That's where ZeroMQ comes in.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/message-exchanges-using-zeromq/"&gt;Read more…&lt;/a&gt; (6 min remaining to read)&lt;/p&gt;&lt;/section&gt;&lt;/section&gt;</description><category>C</category><category>golang</category><category>ZeroMQ</category><guid>https://alexpacio.github.io/posts/message-exchanges-using-zeromq/</guid><pubDate>Mon, 27 Jan 2025 18:00:00 GMT</pubDate></item><item><title>Building a Lightweight Node.js Background Job Scheduler: A Practical Solution for Simple Web Applications</title><link>https://alexpacio.github.io/posts/lightweight-nodejs-background-job-scheduler/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;section id="building-a-lightweight-node-js-background-job-scheduler"&gt;
&lt;h2&gt;Building a Lightweight Node.js Background Job Scheduler&lt;/h2&gt;
&lt;p&gt;As developers, we often come across situations where a fully-fledged background job system, with all its bells and whistles, might be overkill for our project needs. This was the case for me when I built a custom background job scheduler in &lt;strong&gt;TypeScript&lt;/strong&gt; and &lt;strong&gt;Node.js&lt;/strong&gt;, designed to handle essential tasks without the overhead of larger, more complex solutions.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/lightweight-nodejs-background-job-scheduler/"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/section&gt;</description><category>Background Jobs</category><category>Docker</category><category>Node.js</category><category>Telegram</category><category>TypeScript</category><guid>https://alexpacio.github.io/posts/lightweight-nodejs-background-job-scheduler/</guid><pubDate>Thu, 10 Oct 2024 12:00:00 GMT</pubDate></item><item><title>Full-fledged API + e2e tests + benchmark + IaC + Helm charts + more as an (interesting) exercise!</title><link>https://alexpacio.github.io/posts/python-k8s-api/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;div&gt;&lt;p&gt;Last week, I was contacted for a coding challenge. The project seemed interesting, so I decided to take it on. At the very least, I would learn something new, which I was eager to explore: Pulumi, k6, FastAPI and some fancy modern things that make you look like a cool dev!&lt;/p&gt;
&lt;p&gt;The project involved creating a simple REST API in Python, which needed to be packaged with Helm, ready for deployment in a Kubernetes (K8s) cluster, and including all the essential tools required.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/python-k8s-api/"&gt;Read more…&lt;/a&gt; (2 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>cloud-native</category><category>fastapi</category><category>k6</category><category>k8s</category><category>kubernetes</category><category>pulumi</category><guid>https://alexpacio.github.io/posts/python-k8s-api/</guid><pubDate>Sun, 22 Sep 2024 12:19:03 GMT</pubDate></item><item><title>Hello world!</title><link>https://alexpacio.github.io/posts/hello-world/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;div&gt;&lt;p&gt;This is my first post! I'm excited to start sharing tips on backend development, cloud computing, and more.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/hello-world/"&gt;Read more…&lt;/a&gt; (1 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><guid>https://alexpacio.github.io/posts/hello-world/</guid><pubDate>Sat, 21 Sep 2024 14:41:03 GMT</pubDate></item></channel></rss>