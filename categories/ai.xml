<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Alessandro's View (Posts about ai)</title><link>https://alexpacio.github.io/</link><description></description><atom:link href="https://alexpacio.github.io/categories/ai.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="mailto:alexpacio91 at gmail dot com"&gt;Alessandro Bolletta&lt;/a&gt; </copyright><lastBuildDate>Sun, 24 Aug 2025 18:11:17 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>On the Phenomenology of Coding Agents</title><link>https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;section id="on-the-phenomenology-of-coding-agents"&gt;
&lt;h2&gt;On the Phenomenology of Coding Agents&lt;/h2&gt;
&lt;p&gt;Large Language Models have undoubtedly revolutionized how we interact with technology. They are, at their core, supercharged search engines with remarkable encoding and decoding capabilities. You speak to them in natural language, and they respond with perfect written text, flawless speech synthesis, or sophisticated image generation. Their utility is undeniable, yet we must acknowledge a fundamental truth: they cannot think in the human sense of the word.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/section&gt;</description><category>ai</category><category>coding</category><category>development</category><category>llm</category><category>programming</category><guid>https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/</guid><pubDate>Sun, 24 Aug 2025 10:00:00 GMT</pubDate></item></channel></rss>