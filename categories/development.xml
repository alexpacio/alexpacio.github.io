<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Alessandro's View (Posts about development)</title><link>https://alexpacio.github.io/</link><description></description><atom:link href="https://alexpacio.github.io/categories/development.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><copyright>Contents © 2025 &lt;a href="mailto:alexpacio91 at gmail dot com"&gt;Alessandro Bolletta&lt;/a&gt; </copyright><lastBuildDate>Sun, 24 Aug 2025 18:24:21 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>On the Phenomenology of Coding Agents</title><link>https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;div&gt;&lt;p&gt;Large Language Models have undoubtedly revolutionized how we interact with technology. They are, at their core, supercharged search engines with remarkable encoding and decoding capabilities. You speak to them in natural language, and they respond with perfect written text, flawless speech synthesis, or sophisticated image generation. Their utility is undeniable, yet we must acknowledge a fundamental truth: they cannot think in the human sense of the word.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/"&gt;Read more…&lt;/a&gt; (4 min remaining to read)&lt;/p&gt;&lt;/div&gt;</description><category>ai</category><category>coding</category><category>development</category><category>llm</category><category>programming</category><guid>https://alexpacio.github.io/posts/on-the-phenomenology-of-coding-agents/</guid><pubDate>Sun, 24 Aug 2025 10:00:00 GMT</pubDate></item><item><title>The Hidden Costs of Static Linking and Containerization: A Critical Analysis</title><link>https://alexpacio.github.io/posts/hidden-costs-static-linking-containerization/</link><dc:creator>Alessandro Bolletta</dc:creator><description>&lt;section id="statically-linked-programs-are-the-evil"&gt;
&lt;h2&gt;Statically-linked Programs are the evil&lt;/h2&gt;
&lt;p&gt;The trend toward static linking represents a fundamental regression in software engineering principles. By bundling every dependency directly into the executable, we're not just bloating our binaries - we're actively dismantling decades of progress in software modularization. Each statically linked program becomes an island, disconnected from the ecosystem of shared improvements and security updates.&lt;/p&gt;
&lt;p&gt;Consider what happens when a critical vulnerability is discovered in a commonly used library. In a properly designed system using shared libraries, a single system update would protect all applications simultaneously. Instead, with static linking, we must embark on a complex and error-prone process of identifying every affected program, rebuilding each one individually, and ensuring they all get redeployed.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://alexpacio.github.io/posts/hidden-costs-static-linking-containerization/"&gt;Read more…&lt;/a&gt; (7 min remaining to read)&lt;/p&gt;&lt;/section&gt;</description><category>containers</category><category>development</category><category>infrastructure</category><category>security</category><category>static-linking</category><guid>https://alexpacio.github.io/posts/hidden-costs-static-linking-containerization/</guid><pubDate>Sun, 02 Feb 2025 07:00:00 GMT</pubDate></item></channel></rss>